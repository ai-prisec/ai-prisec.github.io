---
permalink: /
author_profile: true
image: ../images/photo.jpeg
title: Privacy and Security in ML Seminars
---

<br>This is the homepage of the **Privacy & Security in Machine Learning (PriSec-ML) Interest Group**. It brings together researchers and practitioners around the world broadly interested in this topic. For the time being, it features recurring seminars, a couple of times a month, always on Wednesdays, around 1.30 PM (London Time).  

### Get Involved
- Subscribe to our [mailing list](https://www.jiscmail.ac.uk/cgi-bin/webadmin?SUBED1=PRISEC-ML&A=1) to receive to seminar and job announcements
- Join our [Slack](https://prisec-ml.slack.com) by using this [link](https://join.slack.com/t/prisec-ml/shared_invite/zt-y02o7shc-Ef~5IRsEyNwCzvZkfjy7lg). This is particularly useful for students, who maintain an active working group with monthly (virtual) meet-ups.
- Subscribe to our [YouTube channel](http://youtube.com/c/PrivacyandMachineLearningInterestGroup) where we live stream talks and keep recordings of previous talks


### Upcoming Seminars

<img src="../images/sara.png" style="float:right;width:100px;height:100px;margin-top:00px">
- 10 November 2021, 16:00 ([UK time](https://www.timeanddate.com/worldclock/fixedtime.html?msg=Seminar&iso=20211110T1600&p1=136))  
**Dr. Sara Hooker (Google Brain)**  
The myth of the interpretable, robust, compact and high performance DNN  
[[Zoom Registration](https://ucl.zoom.us/meeting/register/tJYodO6vqjkvHNcl449ZmWi68H0YySLnjkrT)] [[Live Stream](https://youtu.be/BZ3FDiXkP78)]<details><br>**Abstract:**<br>To-date, a discussion around the relative merits of different compression methods has centered on the trade-off between level of compression and top-line metrics. Along this dimension, compression techniques such as pruning and quantization are remarkably successful. It is possible to prune or heavily quantize with negligible decreases to test-set accuracy. However, top-line metrics obscure critical differences in generalization between compressed and non-compressed networks. In this talk, we will go beyond test-set accuracy and discuss some of my recent work measuring the trade-offs between compression, robustness and algorithmic bias. Characterizing these trade-offs provide insight into how capacity is used in deep neural networks -- the majority of parameters are used to represent a small fraction of the training set.<br><br>**Bio:**<br>[https://www.sarahooker.me](https://www.sarahooker.me)<br></details>

<img src="../images/reza.jpeg" style="float:right;width:100px;height:100px;margin-top:00px">
- 17 November 2021, 13:30 ([UK time](https://www.timeanddate.com/worldclock/fixedtime.html?msg=Seminar&iso=20211117T1330&p1=136))  
**Prof. Reza Shokri (National University of Singapore)**  
Privacy Auditing in Machine Learning  
[[Zoom Registration](https://ucl.zoom.us/meeting/register/tJYpduCoqDIsHNdg26Sb1Bc8s2GZkKF-mir1)] [[Live Stream](https://youtu.be/Ud7-sSJTG2k)]<details><br>**Abstract:**<br>TBA<br><br>**Bio:**<br>[https://www.comp.nus.edu.sg/~reza/](https://www.comp.nus.edu.sg/~reza/)<br></details>

<img src="../images/eugene.jpg" style="float:right;width:100px;height:100px;margin-top:00px">
- 1 December 2021, 13:30 ([UK time](https://www.timeanddate.com/worldclock/fixedtime.html?msg=Seminar&iso=20211201T1330&p1=136))  
**Eugene Bagdasaryan (Cornell Tech and Apple)**  
TBD  
[[Zoom Registration]()] [[Live Stream]()]<details><br>**Abstract:**<br>TBA<br><br>**Bio:**<br>[https://www.cs.cornell.edu/~eugene/](https://www.cs.cornell.edu/~eugene/)<br></details>

<img src="../images/luca.jpeg" style="float:right;width:100px;height:100px;margin-top:00px">
- 8 December 2021, 13:30 ([UK time](https://www.timeanddate.com/worldclock/fixedtime.html?msg=Seminar&iso=20211208T1330&p1=136))  
**Dr. Luca Melis**  
Differentially Private Query Release Through Adaptive Projection  
[[Zoom Registration]( https://ucl.zoom.us/meeting/register/tJAucuurqzwiH9xXIeN07Esj0GvYdKf3DwVQ)] [[Live Stream](https://youtu.be/azF_CDX7zvg)]<details><br>**Abstract:**<br>We propose, implement, and evaluate a new algorithm for releasing answers to very large numbers of statistical queries like k-way marginals, subject to differential privacy. Our algorithm makes adaptive use of a continuous relaxation of the Projection Mechanism, which answers queries on the private dataset using simple perturbation, and then attempts to find the synthetic dataset that most closely matches the noisy answers. We use a continuous relaxation of the synthetic dataset domain which makes the projection loss differentiable, and allows us to use efficient ML optimization techniques and tooling. Rather than answering all queries up front, we make judicious use of our privacy budget by iteratively and adaptively finding queries for which our (relaxed) synthetic data has high error, and then repeating the projection. We perform extensive experimental evaluations across a range of parameters and datasets, and find that our method outperforms existing algorithms in many cases, especially when the privacy budget is small or the query class is large. In [ICML 2021](https://arxiv.org/abs/2103.06641).
<br><br>**Bio:**<br>I am a Research Scientist at Facebook in New York City. My research interests are in the fields of machine learning, privacy and cloud security. I received my BSc. and MSc. in Computer Engineering from University of Florence, then, in 2018, a PhD in Computer Science from University College London under the supervision of Prof. Emiliano De Cristofaro.
<br></details>

Google Calendar: \[[html](https://calendar.google.com/calendar/embed?src=oormvn3d4hah013g6gd39pjpfk%40group.calendar.google.com&ctz=Europe%2FLondon)\] \[[ics](https://calendar.google.com/calendar/ical/oormvn3d4hah013g6gd39pjpfk%40group.calendar.google.com/public/basic.ics)\]


### Past Seminars

<img src="../images/konrad.jpeg" style="float:right;width:100px;height:100px;margin-top:0px">
- 13 October 2021, 13:00 ([UK time](https://www.timeanddate.com/worldclock/fixedtime.html?msg=Seminar&iso=20211013T13&p1=136))  
**Prof. Konrad Rieck (Technische Universit√§t Braunschweig)**  
Adversarial Preprocessing: Image-Scaling Attacks in Machine Learning  
[[Zoom Registration](https://ucl.zoom.us/meeting/register/tJEoc-itqzwoE9wIgC6gpR5WAMIWlt0dgFeB)] [[Live Stream](https://youtu.be/kCKayHjZd3E)]<details><br>**Abstract:**<br>The remarkable advances of machine learning are overshadowed by attacks that thwart its proper operation. While previous work has mainly focused on attacking learning algorithms directly, another weak spot in intelligent systems has been overlooked: preprocessing. As an example of this threat, I present a recent class of attacks against image scaling. These attacks are agnostic to learning algorithms and affect the preprocessing of all vision systems that use vulnerable implementations, including versions of TensorFlow, OpenCV, and Pillow. Based on a root-cause analysis of the vulnerabilities, I introduce novel defenses that effectively block image-scaling attacks in practice and can be easily added to existing systems.<br><br>**Bio:**<br>[https://www.tu-braunschweig.de/en/sec/team/rieck](https://www.tu-braunschweig.de/en/sec/team/rieck)<br></details>


### Previous Iteration
This is a reboot of the [Turing Institute](https://www.turing.ac.uk)'s interest group in Privacy and Machine Learning ([old page](https://www.turing.ac.uk/research/interest-groups/privacy-preserving-data-analysis)). We have branched out and expanded to topics at the intersection of Security (not "just" Privacy) and Machine Learning.


<iframe width="560" height="315" src="https://www.youtube.com/embed/Dn_NkH-IEVA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Organizers
- [Prof. Emiliano De Cristofaro](https://emilianodc.com/), UCL  
- [Dr. Giovanni Cherubin](https://giocher.com/), Alan Turing Institute  
- [Prof. Lorenzo Cavallaro](https://s2lab.cs.ucl.ac.uk/people/sullivan), UCL  
- [Dr. Vasilis Mavroudis](https://mavroud.is/), Alan Turing Institute  

